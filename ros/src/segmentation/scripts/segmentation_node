#! /usr/bin/env python

# MIT License. Must include author and license in your work.

# Copyright (c) 2017-2018 Yongyang Nie

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""
Run a semantic segmentation node.
This ROS node uses the object detector class to run detection.
"""

from segmentor import Segmentor
import cv2
from PIL import Image
import numpy as np
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from segmentation.msg import SegmentationResult
import time


class ObjectDetectionNode:

    def __init__(self):

        rospy.init_node('segmentation_node')

        # ROS subscribers
        rospy.Subscriber("/zed/rgb/image_raw_color", Image, callback=self.image_update_callback, queue_size=5)
        rospy.Subscriber("/zed/depth/depth_registered", Image, callback=self.depth_image_update_callback, queue_size=5)

        self.current_frame = None
        self.depth_frame = None
        self.bridge = CvBridge()

        # Get ROS parameters
        self.weight_path = rospy.get_param("/segmentation_node/weight_path")
        self.visualize = rospy.get_param("/segmentation_node/visualization")
        self.input_img_height = rospy.get_param("/segmentation_node/input_img_height")
        self.input_img_width = rospy.get_param("/segmentation_node/input_img_width")
        self.output_img_height = rospy.get_param("/segmentation_node/output_img_height")
        self.output_img_width = rospy.get_param("/segmentation_node/output_img_width")

        self.segmentor = Segmentor(weight_path=self.weight_path)

        # Setup publishers
        segmentation_image_pub = rospy.Publisher('/segmentation/output/visualization/', Image, queue_size=5)
        segmentation_results_pub = rospy.Publisher('/segmentation/output/full', SegmentationResult, queue_size=5)
        segmentation_road_pub = rospy.Publisher('/segmentation/output/road', Image, queue_size=5)

        rate = rospy.Rate(24)

        # Running ROS loop
        rospy.loginfo("Semantic Segmentation Started")
        rospy.loginfo("Visualization: " + str(self.visualize))
        rospy.loginfo("v1.8.0")

        while not rospy.is_shutdown():

            if self.current_frame is not None and self.depth_frame is not None:

                # start = time.time()
                output, visualization = self.segmentor.semantic_segmentation(self.current_frame, visualize=self.visualize,
                                                                             depth_image=self.depth_frame)

                # end = time.time()
                # rospy.loginfo("frame rate: " + str(1 / (end - start)))

                if self.visualize:
                    viz_msg = self.bridge.cv2_to_imgmsg(visualization, "bgr8")  # convert image to ROS msg type
                    segmentation_image_pub.publish(viz_msg)                     # publish the visualization image

                # publish road
                road_msg = self.get_road_image(output)
                segmentation_road_pub.publish(road_msg)

                # publish all segmentation results
                msg = self.convert_results_to_message(output)                   # convert output to ROS msg type
                segmentation_results_pub.publish(msg)                           # publish using publisher

            rate.sleep()

    def image_update_callback(self, data):

        try:
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            raise e

        self.current_frame = cv_image

    def depth_image_update_callback(self, data):

        try:
            # The depth image is a single-channel float32 image
            depth_image = self.bridge.imgmsg_to_cv2(data, "32FC1")
        except CvBridgeError as e:
            raise e

        # Convert the depth image to a Numpy array since most cv2 functions
        # require Numpy arrays.
        depth_image[depth_image == np.inf] = 20.0
        depth_image[depth_image == -np.inf] = 0.0
        depth_image[depth_image == np.nan] = 0
        norm_image = cv2.normalize(depth_image, None, 0, 1, norm_type=cv2.NORM_MINMAX)

        norm_image = 1.0 - norm_image

        output = np.zeros((depth_image.shape[0], depth_image.shape[1], 3))
        output[:, :, 0] = norm_image
        output[:, :, 1] = norm_image
        output[:, :, 2] = norm_image

        # cv2.imshow('depth_image', output)
        # cv2.waitKey(0)

        self.depth_frame = output

    def convert_results_to_message(self, segmentation_output):

        msg = SegmentationResult()
        msg.width = self.output_img_width
        msg.height = self.output_img_height
        msg.depth = segmentation_output.shape[2]
        for i in range(msg.depth):
            split = np.array(segmentation_output[:, :, i], dtype=np.uint8)  # must convert seg output to uint8
            img_msg = self.bridge.cv2_to_imgmsg(split, "mono8")             # convert image to ROS msg type
            msg.data.append(img_msg)

        return msg

    def get_road_image(self, output):

        output[:, :, 7][output[:, :, 7] > 0.5] = 1
        output[:, :, 7][output[:, :, 7] <= 0.5] = 0
        output[:, :, 7] *= 255
        road_img = cv2.resize(output[:, :, 7], (1920, 1080))

        np_mat = np.array(road_img, dtype=np.uint8)
        road_msg = self.bridge.cv2_to_imgmsg(np_mat, 'mono8')  # road is index 7, side walk is index 8

        return road_msg

if __name__ == "__main__":

    try:
        ObjectDetectionNode()
    except rospy.ROSInterruptException:
        pass
